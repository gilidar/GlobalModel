{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "congealing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1m4GMbfq9jYvuLLrq_c_vte96G_eiiQH_",
      "authorship_tag": "ABX9TyP+AAtsGzHAmxw3CzrHMYuo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gilidar/GlobalModel/blob/main/congealing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "T7b3NKAmjBS5"
      },
      "source": [
        "#@title Check GPU & memory allocation\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('You are not using the GPU')\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.\\n')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.\\n')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2gwlIzIZEuc"
      },
      "source": [
        "#@title Download required packacges\n",
        "!pip install kneed\n",
        "!pip install hdf5storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "dSyi0QvF_C1z"
      },
      "source": [
        "#@title Load libraries\n",
        "\n",
        "# Reproducibility first\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(2)\n",
        "####################\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox, TextArea\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Layer, Flatten, Dense, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, ReLU, LeakyReLU, Reshape, BatchNormalization\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, LambdaCallback, EarlyStopping, LearningRateScheduler\n",
        "import math\n",
        "import pickle\n",
        "from numpy.random import randn\n",
        "from collections import defaultdict\n",
        "import hdf5storage\n",
        "from scipy.stats import norm\n",
        "from scipy.io import savemat\n",
        "from scipy import ndimage\n",
        "import itertools\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHZvYmA9t8iR"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBY9f6KgElbM"
      },
      "source": [
        "datatype = 'cell'\n",
        "\n",
        "NEPOCH = 10000 \n",
        "batch_size = 64 # size of mini-batch\n",
        "dat_dim = 128  # image width/height\n",
        "dat_ch = 1   # number of channels (1=monochrome)\n",
        "latent_dim = 64  # size of latent variable\n",
        "k = 1; gamma = 1\n",
        "iep = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg8gUUO38UL8",
        "cellView": "form"
      },
      "source": [
        "#@title Models \n",
        "\n",
        "def build_aligner(): #Try DestNET for localization?<<<<<<<<<\n",
        "    input = Input(shape=(in_dim, in_dim, num_ch))\n",
        "    theta = Localization()(input)\n",
        "    output = BilinearInterpolation(height=in_dim, width=in_dim)([encoder_input, theta]) #Assumes single channel<<<<<<<<<\n",
        "    rotNET = Model(input, output) \n",
        "    return rotNET\n",
        "\n",
        "def build_ae(latent_dim): \n",
        "    # Encoder\n",
        "    conv_end_dim = int(in_dim/8)\n",
        "    conv_end_dim2 = conv_end_dim*conv_end_dim\n",
        "    encoder_input = Input(shape=(in_dim, in_dim, num_ch))\n",
        "    encoded = encoder_input\n",
        "    encoded = Conv2D(128, 3, activation='tanh', strides=2, padding='same')(encoded)\n",
        "    encoded = Conv2D(128, 3, activation='tanh', strides=2, padding='same')(encoded)\n",
        "    encoded = Conv2D(128, 3, activation='tanh', strides=2, padding='same')(encoded)\n",
        "    encoded = Conv2D(256, 1, activation='tanh', padding='same')(encoded)\n",
        "    encoded = Conv2D(64, 1, activation='tanh', padding='same')(encoded)\n",
        "    encoded = Conv2D(1, 1, activation='tanh', padding='same')(encoded)\n",
        "    encoded = Flatten()(encoded)\n",
        "    encoder_output = Dense(latent_dim, activation='sigmoid')(encoded)\n",
        "    encoder = Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "    # Decoder\n",
        "    decoder_input = Input(shape=(latent_dim,))\n",
        "    decoded = decoder_input\n",
        "    decoded = Dense(conv_end_dim2, activation='tanh')(decoded)\n",
        "    decoded = Reshape(conv_end_dim, conv_end_dim, 1)(decoded)\n",
        "    decoded = Conv2D(1, 1, activation='tanh', padding='same')(decoded)\n",
        "    decoded = Conv2D(64, 1, activation='tanh', padding='same')(decoded)\n",
        "    decoded = Conv2D(256, 1, activation='tanh', padding='same')(decoded)\n",
        "    decoded = Conv2D(128, 3, activation='tanh', padding='same')(decoded)\n",
        "    decoded = UpSampling2D((2, 2))(decoded)\n",
        "    decoded = Conv2D(128, 3, activation='tanh', padding='same')(decoded)\n",
        "    decoded = UpSampling2D((2, 2))(decoded)\n",
        "    decoded = Conv2D(128, 3, activation='tanh', padding='same')(decoded)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoded)\n",
        "    decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "    return encoder, decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transformer Module\n",
        "\n",
        "class Localization(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Localization, self).__init__()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc1 = tf.keras.layers.Dense(20, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(6, activation=None, bias_initializer=tf.keras.initializers.constant([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), kernel_initializer='zeros')\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        print(\"Building Localization Network with input shape:\", input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [None, 6]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        theta = self.fc2(x)\n",
        "        theta = tf.keras.layers.Reshape((2, 3))(theta)\n",
        "        return theta\n",
        "        \n",
        "class BilinearInterpolation(tf.keras.layers.Layer):\n",
        "    def __init__(self, height=40, width=40):\n",
        "        super(BilinearInterpolation, self).__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [None, self.height, self.width, 1]\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'height': self.height,\n",
        "            'width': self.width,\n",
        "        }\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        print(\"Building Bilinear Interpolation Layer with input shape:\", input_shape)\n",
        "\n",
        "    def advance_indexing(self, inputs, x, y):\n",
        "        '''\n",
        "        Numpy like advance indexing is not supported in tensorflow, hence, this function is a hack around the same method\n",
        "        '''        \n",
        "        shape = tf.shape(inputs)\n",
        "        batch_size, _, _ = shape[0], shape[1], shape[2]\n",
        "        \n",
        "        batch_idx = tf.range(0, batch_size)\n",
        "        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
        "        b = tf.tile(batch_idx, (1, self.height, self.width))\n",
        "        indices = tf.stack([b, y, x], 3)\n",
        "        return tf.gather_nd(inputs, indices)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        images, theta = inputs\n",
        "        homogenous_coordinates = self.grid_generator(batch=tf.shape(images)[0])\n",
        "        return self.interpolate(images, homogenous_coordinates, theta)\n",
        "\n",
        "    def grid_generator(self, batch):\n",
        "        x = tf.linspace(-1, 1, self.width)\n",
        "        y = tf.linspace(-1, 1, self.height)\n",
        "            \n",
        "        xx, yy = tf.meshgrid(x, y)\n",
        "        xx = tf.reshape(xx, (-1,))\n",
        "        yy = tf.reshape(yy, (-1,))\n",
        "        homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])\n",
        "        homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)\n",
        "        homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])\n",
        "        homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)\n",
        "        return homogenous_coordinates\n",
        "    \n",
        "    def interpolate(self, images, homogenous_coordinates, theta):\n",
        "\n",
        "        with tf.name_scope(\"Transformation\"):\n",
        "            transformed = tf.matmul(theta, homogenous_coordinates)\n",
        "            transformed = tf.transpose(transformed, perm=[0, 2, 1])\n",
        "            transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])\n",
        "                \n",
        "            x_transformed = transformed[:, :, :, 0]\n",
        "            y_transformed = transformed[:, :, :, 1]\n",
        "                \n",
        "            x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5\n",
        "            y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5\n",
        "\n",
        "        with tf.name_scope(\"VariableCasting\"):\n",
        "            x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)\n",
        "            x1 = x0 + 1\n",
        "            y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)\n",
        "            y1 = y0 + 1\n",
        "\n",
        "            x0 = tf.clip_by_value(x0, 0, self.width-1)\n",
        "            x1 = tf.clip_by_value(x1, 0, self.width-1)\n",
        "            y0 = tf.clip_by_value(y0, 0, self.height-1)\n",
        "            y1 = tf.clip_by_value(y1, 0, self.height-1)\n",
        "            x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32)-1.0)\n",
        "            y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32)-1)\n",
        "\n",
        "        with tf.name_scope(\"AdvanceIndexing\"):\n",
        "            Ia = self.advance_indexing(images, x0, y0)\n",
        "            Ib = self.advance_indexing(images, x0, y1)\n",
        "            Ic = self.advance_indexing(images, x1, y0)\n",
        "            Id = self.advance_indexing(images, x1, y1)\n",
        "\n",
        "        with tf.name_scope(\"Interpolation\"):\n",
        "            x0 = tf.cast(x0, dtype=tf.float32)\n",
        "            x1 = tf.cast(x1, dtype=tf.float32)\n",
        "            y0 = tf.cast(y0, dtype=tf.float32)\n",
        "            y1 = tf.cast(y1, dtype=tf.float32)\n",
        "                            \n",
        "            wa = (x1-x) * (y1-y)\n",
        "            wb = (x1-x) * (y-y0)\n",
        "            wc = (x-x0) * (y1-y)\n",
        "            wd = (x-x0) * (y-y0)\n",
        "\n",
        "            wa = tf.expand_dims(wa, axis=3)\n",
        "            wb = tf.expand_dims(wb, axis=3)\n",
        "            wc = tf.expand_dims(wc, axis=3)\n",
        "            wd = tf.expand_dims(wd, axis=3)\n",
        "                        \n",
        "        return tf.math.add_n([wa*Ia + wb*Ib + wc*Ic + wd*Id])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cP1ebfkDgWZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ4IBIMY9CUw"
      },
      "source": [
        "#@title More Funcs\n",
        "\n",
        "def build_weighing_vector(k, b):\n",
        "    w = tf.zeros([b], tf.int32)\n",
        "    sum = 0.0\n",
        "    for i in range(b):\n",
        "      w[i] = math.pow(i+1,k)\n",
        "      sum = sum + w[i]\n",
        "    w = w/sum\n",
        "    w_stack = tf.tile(w, batch_size)\n",
        "    return w_stack\n",
        "\n",
        "def train_val_split(X_, Y_, ratio=0.8,seed=42):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    L = len(X_)\n",
        "    perm = rnd.permutation(L)\n",
        "    train_idx = perm[:int(ratio * L)]\n",
        "    val_idx = perm[int(ratio * L):]\n",
        "    return X_[train_idx], X_[val_idx], Y_[train_idx], Y_[val_idx]\n",
        "\n",
        "def saveMODEL(model, save_loc):\n",
        "  model.save_weights(save_loc + 'model', save_format='tf')\n",
        "  print(runtype + ' model saved...')\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx8s1T7BTPQA",
        "cellView": "form"
      },
      "source": [
        "#@title Training\n",
        "\n",
        "@tf.function\n",
        "class CONGEAL(keras.Model):\n",
        "    def __init__(self, aligner, encoder, decoder, **kwargs):\n",
        "        super(CONGEAL, self).__init__(**kwargs)\n",
        "        self.aligner = aligner\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.transformation_loss_tracker = keras.metrics.Mean(name=\"transformation_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.compactness_loss_tracker = keras.metrics.Mean(name=\"compactness_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.transformation_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.compactness_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.device('/gpu:0'):\n",
        "\n",
        "          #Train aligner\n",
        "          with tf.GradientTape() as tape:\n",
        "              aligned_data = self.aligner(data)\n",
        "              transformation_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.MeanAbsoluteError(aligned_data, GT_stack), axis=(1, 2)))\n",
        "          grads = tape.gradient(transformation_loss, self.aligner.trainable_weights)\n",
        "          self.optimizer.apply_gradients(zip(grads, self.aligner.trainable_weights))\n",
        "\n",
        "          #Train all\n",
        "          with tf.GradientTape() as tape:\n",
        "              aligned_data = self.aligner(data)\n",
        "              z = self.encoder(aligned_data)\n",
        "              reconstruction = self.decoder(z)\n",
        "              compactness_loss = tf.tensordot(w,z)\n",
        "              compactness_loss = tf.reduce_mean(tf.reduce_sum(compactness_loss, axis=1))\n",
        "              reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.MeanAbsoluteError(aligned_data, reconstruction), axis=(1, 2)))\n",
        "              ae_loss = reconstruction_loss  + gamma*compactness_loss\n",
        "          grads = tape.gradient(ae_loss, self.trainable_weights)\n",
        "          self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "          #Metrics tracking\n",
        "          self.total_loss_tracker.update_state(ae_loss + transformation_loss)\n",
        "          self.transformation_loss_tracker.update_state(transformation_loss)\n",
        "          self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "          self.compactness_loss_tracker.update_state(compactness_loss)\n",
        "\n",
        "          Total_loss = self.total_loss_tracker.result().numpy()\n",
        "          TR_loss = self.transformation_loss_tracker.result().numpy()\n",
        "          Recon_loss = self.reconstruction_loss_tracker.result().numpy()\n",
        "          CP_loss = self.compactness_loss_tracker.result().numpy()\n",
        "\n",
        "          del tape\n",
        "\n",
        "          return {\n",
        "              \"loss\": self.total_loss_tracker.result(),\n",
        "              \"transformation_loss\": self.transformation_loss_tracker.result(),\n",
        "              \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "              \"compactness_loss\": self.compactness_loss_tracker.result(),\n",
        "          }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVsh8G5Cz7ft",
        "cellView": "form"
      },
      "source": [
        "#@title Plot losses \n",
        "\n",
        "class PlotLosses(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.logs = []\n",
        "        if mode == 'ReTrain':\n",
        "          info_file = open(save_loc + runtype + \"info.pkl\", \"rb\"); \n",
        "          info = pickle.load(info_file); info_file.close()\n",
        "          self.i = info[\"ep\"][-1]\n",
        "          self.x = info[\"ep\"]\n",
        "          self.total_loss = info[\"Loss\"]\n",
        "          self.recon_loss = info[\"Recon Loss\"]\n",
        "          self.transform_loss = info[\"TR Loss\"]\n",
        "          self.compact_loss = info[\"CP Loss\"]\n",
        "        else:\n",
        "          self.i = 0\n",
        "          self.x = []\n",
        "          self.total_loss = []\n",
        "          self.recon_loss = []\n",
        "          self.transform_loss = []\n",
        "          self.compact_loss = []\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.total_loss.append(Total_loss)\n",
        "        self.recon_loss.append(Recon_loss)\n",
        "        self.transform_loss.append(TR_loss)\n",
        "        self.compact_loss.append(CP_loss)\n",
        "        self.i += 1\n",
        "        fig = plt.figure(figsize=(15, 15))\n",
        "        fig.suptitle('Losses')\n",
        "        gs = fig.add_gridspec(2, 2)\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        ax1.plot(self.x, self.total_loss, label=\"total loss\")\n",
        "        ax1.set_title('Total loss')\n",
        "        ax3 = fig.add_subplot(gs[1, 0])\n",
        "        ax3.plot(self.x, self.recon_loss, label=\"reconstruction loss\")\n",
        "        ax3.set_title('Reconstruction loss')\n",
        "        ax2 = fig.add_subplot(gs[1, 1])\n",
        "        ax2.plot(self.x, self.compact_loss, label=\"compactness loss\")\n",
        "        ax2.set_title('Compactness loss')\n",
        "        ax4 = fig.add_subplot(gs[0, 1])\n",
        "        ax4.plot(self.x, self.transform_loss, label=\"Transformation loss\")\n",
        "        ax4.set_title('Transformation loss')\n",
        "        plt.savefig(save_loc + runtype + 'Loss.jpg')\n",
        "        plt.show()\n",
        "        plt.close('all')\n",
        "        # Save loss and epoch vectors\n",
        "        training_info = {\"ep\": self.x, \n",
        "                         \"Loss\":self.total_loss, \n",
        "                         \"Recon Loss\":self.recon_loss, \n",
        "                         \"TR Loss\":self.transform_loss,\n",
        "                         \"CP Loss\": self.compact_loss}\n",
        "        info_file = open(save_loc + runtype + \"info.pkl\", \"wb\");\n",
        "        pickle.dump(training_info, info_file);\n",
        "        info_file.close()\n",
        "        print(\"Model info saved.\")\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDOzBDWcS8xJ",
        "cellView": "form"
      },
      "source": [
        "#@title Visualization functions\n",
        "\n",
        "def showdataset(x, sqrtn_in = 5, seed = 42, type = ''):\n",
        "    if datatype == 'mnist':\n",
        "      plt.gray()\n",
        "    sqrtn_max = 5\n",
        "    sqrtn = min(sqrtn_in, sqrtn_max)\n",
        "    tot_ims = sqrtn**2\n",
        "    np.random.seed(seed)\n",
        "    inds = np.random.choice(x.shape[0], sqrtn**2, replace=False)\n",
        "    fig, axs = plt.subplots(sqrtn, sqrtn, figsize=(10, 10))\n",
        "    fig.suptitle('Random images from ' + type + ' dataset')\n",
        "    for i in range(tot_ims):\n",
        "        ind1, ind2 = divmod(i, sqrtn)\n",
        "        if dat_ch>1:\n",
        "          axs[ind1, ind2].imshow(x[inds[i]].reshape(dat_dim, dat_dim, dat_ch))\n",
        "        else:\n",
        "          axs[ind1, ind2].imshow(x[inds[i]].reshape(dat_dim, dat_dim)) \n",
        "        axs[ind1, ind2].axis('off')\n",
        "    plt.show()\n",
        "    #plt.savefig(save_loc + 'Random images from ' + type + ' dataset')\n",
        "    plt.close('all')\n",
        "    return\n",
        "\n",
        "def imagesc(im1, title=''):\n",
        "    dat_dim = im1.shape[1]\n",
        "    if dat_ch>1:\n",
        "      ax1.imshow(im1.reshape(dat_dim, dat_dim, dat_ch))\n",
        "    else:\n",
        "      ax1.imshow(im1.reshape(dat_dim, dat_dim))\n",
        "    ax1.set_title(title)\n",
        "    ax1.axis('off')\n",
        "    plt.show()\n",
        "    plt.close('all')\n",
        "    return\n",
        "\n",
        "def show_pair(im1, im2, title=''):\n",
        "    plt.jet()\n",
        "    fig, [ax1,ax2] = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    fig.suptitle(title)\n",
        "    ##\n",
        "    if dat_ch>1:\n",
        "      ax1.imshow(im1.reshape(NX, NY, NC))\n",
        "    else:\n",
        "      ax1.imshow(im1.reshape(NX, NY))\n",
        "    ax1.axis('off')\n",
        "    ##\n",
        "    if dat_ch>1:\n",
        "      ax2.imshow(im2.reshape(NX, NY, NC))\n",
        "    else:\n",
        "      ax2.imshow(im2.reshape(NX, NY))\n",
        "    ax2.axis('off')\n",
        "    plt.show()\n",
        "    plt.close('all')\n",
        "    return\n",
        "\n",
        "def track_images(im1, GT1, aligner, encoder, decoder, epoch, str_mode):\n",
        "    dat_dim = im1.shape[1]\n",
        "    fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Image propagated through network after epoch #' + str(epoch) + 'str_mode')\n",
        "    ##\n",
        "    if dat_ch>1:\n",
        "      ax1.imshow(GT1.reshape(dat_dim, dat_dim, dat_ch))\n",
        "    else:\n",
        "      ax1.imshow(GT1.reshape(dat_dim, dat_dim))\n",
        "    ax1.set_title('GT')\n",
        "    ax1.axis('off')\n",
        "    ##\n",
        "    input_image = im1.reshape(1, dat_dim, dat_dim, dat_ch)\n",
        "    if dat_ch>1:\n",
        "      ax2.imshow(input_image.reshape(dat_dim, dat_dim, dat_ch))\n",
        "    else:\n",
        "      ax2.imshow(input_image.reshape(dat_dim, dat_dim))\n",
        "    ax2.set_title('INPUT')\n",
        "    ax2.axis('off')\n",
        "    ##\n",
        "    aligned_img = aligner(input_image)\n",
        "    if dat_ch>1:\n",
        "      ax3.imshow(aligned_img.reshape(dat_dim, dat_dim, dat_ch))\n",
        "    else:\n",
        "      ax3.imshow(aligned_img.reshape(dat_dim, dat_dim))\n",
        "    ax3.set_title('ALIGNER INFERENCE')\n",
        "    ax3.axis('off')\n",
        "    plt.show()\n",
        "    ##\n",
        "    z = encoder(aligned_img)\n",
        "    decoded_img = decoder(z)\n",
        "    if dat_ch>1:\n",
        "      ax4.imshow(decoded_img.reshape(dat_dim, dat_dim, dat_ch))\n",
        "    else:\n",
        "      ax4.imshow(decoded_img.reshape(dat_dim, dat_dim))\n",
        "    ax4.set_title('AE INFERENCE')\n",
        "    ax4.axis('off')\n",
        "    plt.show()\n",
        "    plt.savefig(save_loc + 'ImagePropagated_epoch#' + str(epoch) + 'str_mode')\n",
        "    return z\n",
        "\n",
        "def showlatentmagnitude(z):\n",
        "    x = np.arange(latent_dim)\n",
        "    plt.plot(x, z, ls='dotted', c='red', lw=5)\n",
        "    plt.show()\n",
        "    plt.savefig(save_loc + 'latentCODE_epoch#' + str(epoch) + 'str_mode')\n",
        "    return\n",
        "\n",
        "def show(x, aligner, encoder, decoder, epoch, str_mode):\n",
        "    i = np.random.randint(0, NSAMPLE)\n",
        "    x_s = x[i]\n",
        "    z = track_images(x_s, GT_stack[0], aligner, encoder, decoder, epoch, str_mode)\n",
        "    showlatentmagnitude(z)\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odW58ZcbPon7",
        "cellView": "form"
      },
      "source": [
        "#@title Result processing functions\n",
        "\n",
        "def rot_array(A):\n",
        "    if rot:\n",
        "      for i in range(A.shape[0]):\n",
        "        temp = ndimage.rotate(A[i,:,:,0], np.random.randint(minangle, maxangle), reshape=False)\n",
        "        temp[temp<0]=0\n",
        "        A[i,:,:,0] = temp\n",
        "    return A\n",
        "\n",
        "\n",
        "def findglobalmodel_from_encoding(originals, encodings, decoder, datatype, show=1):\n",
        "\n",
        "    num_samples = len(encodings)\n",
        "    mean_encoding = sum(encodings)/num_samples\n",
        "    globe_im = decoder.predict(mean_encoding.reshape(encoded_shape))\n",
        "\n",
        "    #Save\n",
        "    glob_model = {\"model\": globe_im}\n",
        "    savemat(save_loc + \"MODEL.mat\", glob_model)\n",
        "    print(\"Global Model saved.\")\n",
        "\n",
        "    if show:\n",
        "        # mpl.rc('image', cmap='gray')\n",
        "        sqrtn = min(math.floor(math.sqrt(num_samples)), 5)\n",
        "        tot_ims = sqrtn ** 2\n",
        "\n",
        "        fig = plt.figure()\n",
        "        fig.set_figheight(6)\n",
        "        fig.set_figwidth(12)\n",
        "\n",
        "        ax1 = plt.subplot2grid(shape=(sqrtn, 2 * sqrtn), loc=(0, 0), colspan=sqrtn, rowspan=sqrtn)\n",
        "        if dat_ch>1:\n",
        "          imgplot = ax1.imshow(globe_im.reshape(dat_dim, dat_dim, dat_ch), aspect='auto', interpolation='none')\n",
        "        else:\n",
        "          imgplot = ax1.imshow(globe_im.reshape(dat_dim, dat_dim), aspect='auto', interpolation='none')\n",
        "        np.random.seed(42)\n",
        "\n",
        "        inds = np.random.choice(originals.shape[0], sqrtn ** 2, replace=False)\n",
        "        for i in range(tot_ims):\n",
        "            ind1, ind2 = divmod(i, sqrtn)\n",
        "            ax = plt.subplot2grid(shape=(sqrtn, 2 * sqrtn), loc=(ind1, ind2 + sqrtn), colspan=1, rowspan=1)\n",
        "            if dat_ch>1:\n",
        "              ax.imshow(originals[inds[i]].reshape(dat_dim, dat_dim, dat_ch))\n",
        "            else:\n",
        "              ax.imshow(originals[inds[i]].reshape(dat_dim, dat_dim))\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.suptitle('Global model for ' + datatype + ' with ' + str(num_samples) + ' images')\n",
        "\n",
        "        if datatype == 'mnist':\n",
        "          plt.gray()\n",
        "        else: \n",
        "          plt.jet()\n",
        "\n",
        "        plt.show()\n",
        "        plt.savefig(save_loc + 'Global model for ' + datatype)\n",
        "        plt.close('all')\n",
        "        \n",
        "    return \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCVEQsQ8EvEA"
      },
      "source": [
        "RUN PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV2Nne6Wx-eR"
      },
      "source": [
        "mode = 'Train' #'Train'/'ReTrain'/'Test'\n",
        "save_loc = 'drive/MyDrive/Colab/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-KjkpBVEyIO"
      },
      "source": [
        "LOAD & PREP DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXQp1bZaEjWO"
      },
      "source": [
        "''' Load dataset '''\n",
        "\n",
        "mat_contents = hdf5storage.loadmat(save_loc+'SIMPLE_SIM_XY.mat') \n",
        "X = np.moveaxis(mat_contents['input1'], 3, 0)\n",
        "max_value = float(X.max())\n",
        "x_train, x_test, _, _ = train_val_split(X, X, ratio=0.9)\n",
        "x_train = x_train.astype('float32') / max_value\n",
        "x_test = x_test.astype('float32') / max_value\n",
        "\n",
        "GT_stack = tf.repeat(x_train[0], batch_size)\n",
        "imagesc(x_train[0], title='GT image for transformation')\n",
        "\n",
        "NSAMPLE = x_train.shape[0]; \n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, tf.expand_dims(label_pos_neg,1))).batch(NBATCH)\n",
        "\n",
        "print(x_train.shape, x_test.shape)\n",
        "showdataset(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jptsXaCcCBqU"
      },
      "source": [
        "Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKXTZ5YZiwLk"
      },
      "source": [
        "aligner = build_aligner()\n",
        "encoder, decoder = build_ae(latent_dim)\n",
        "print(aligner.summary())\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "\n",
        "w = build_weighing_vector(k, latent_dim)\n",
        "print(w)\n",
        "\n",
        "model = CONGEAL(aligner, encoder, decoder)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), run_eagerly=True)   \n",
        "\n",
        "if mode == 'ReTrain' or mode == 'Test':\n",
        "    model.fit(x_train, epochs=1, batch_size=batch_size, verbose=0) #Restore optimizer state before loading weights\n",
        "    model.load_weights(save_loc +  'model')  # Load the state of the old model\n",
        "    #Load info\n",
        "    info_file = open(save_loc + \"info.pkl\", \"rb\"); \n",
        "    info = pickle.load(info_file); info_file.close()\n",
        "    iep = info[\"ep\"][-1]\n",
        "    print(\"Resuming epoch #\" + str(iep) + \"...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train/Test**"
      ],
      "metadata": {
        "id": "_nIsTAVS5gZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if mode == 'Train' or mode == 'ReTrain':\n",
        "    #Callbacks\n",
        "    show_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: show(x_train, aligner, encoder, decoder, epoch, '_training'))\n",
        "    plot_losses = PlotLosses()\n",
        "    save_model = LambdaCallback(on_epoch_end=lambda epoch, logs: saveMODEL(model, save_loc))\n",
        "    #Train\n",
        "    print(\"Training #\" + str(iep) + \"...\")\n",
        "    model.fit(x_train, initial_epoch=iep, epochs=tot_epochs, batch_size=batch_size, \n",
        "            callbacks=[show_callback, plot_losses, save_model])\n",
        "\n",
        "elif mode == 'Test':\n",
        "    print('Testing model...')\n",
        "    # find global model in image domain\n",
        "    # find global model in with VAE"
      ],
      "metadata": {
        "id": "vJnDn-kS5fn1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}